{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm,multivariate_normal\n",
    "from numpy.random import random\n",
    "from math import nan\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import utils as utl\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import aim,em,sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that runs a full experiment according to given experimental settings. Results are returned and saved in a file in the ./Results directory (should exist!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runexperiment(settings):\n",
    "    mugen=settings['mugen']\n",
    "    Sigmagen=settings['Sigmagen']\n",
    "    nexperiments=settings['nexperiments']\n",
    "    nrestarts=settings['nrestarts']\n",
    "    cparams=settings['cparams']\n",
    "    ctypes=settings['ctypes']\n",
    "    \n",
    "    samplesizes=settings['samplesizes']\n",
    "    granularities=settings['granularities']\n",
    "    dim=len(cparams)\n",
    "    initsize=20\n",
    "\n",
    " \n",
    "    timestamp = str(datetime.now())\n",
    "\n",
    "    typestr =\"\"\n",
    "    for tstr in ctypes:\n",
    "        for ttstr in tstr:\n",
    "            typestr+=\"-\"+ttstr\n",
    "        \n",
    "    filename= str(dim)+\"d\" + typestr +\"-\"+timestamp\n",
    "\n",
    "    readme = timestamp + \"\\n\"\n",
    "    readme +=str(dim)+'d with {} coarsening with parameters {}\\n'.format(ctypes,cparams)\n",
    "    if dim==1:\n",
    "        bbs=settings['bbs']\n",
    "        readme +=\"Coarsening bin bounds: {} \\n\".format(bbs)\n",
    "    readme +='Samplesizes: {}\\n'.format(samplesizes)\n",
    "    readme +='Granularities: {}\\n'.format(granularities) \n",
    "    readme +='Restarts: {}\\n'.format(nrestarts) \n",
    "    readme +='Experiments: {}\\n'.format(nexperiments) \n",
    "    readme +='ACA initsize: {}\\n'.format(initsize)\n",
    "\n",
    "\n",
    "\n",
    "    if dim==1:\n",
    "        numparams=2 #mu,Sigma\n",
    "        \n",
    "    if dim==2:\n",
    "        numparams=6 # mu[0],mu[1],Sigma[0,0],Sigma[0,1],Sigma[1,0],Sigma[1,1]\n",
    "\n",
    "   \n",
    "    actualnumbins=len(granularities)\n",
    "\n",
    "    learnedparams_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins,numparams))\n",
    "    klvals_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins))\n",
    "\n",
    "    learnedparams_em_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins,numparams))\n",
    "    klvals_em_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins))\n",
    "\n",
    "    learnedparams_em=np.zeros((nexperiments,nrestarts,len(samplesizes),numparams))\n",
    "    datastats=np.zeros((nexperiments,len(samplesizes),numparams+1)) # aca parameter estimates, missing %\n",
    "    timestats_aim=np.zeros((nexperiments,len(samplesizes),len(granularities)))\n",
    "    timestats_em_aim=np.zeros((nexperiments,len(samplesizes),len(granularities)))\n",
    "    timestats_em=np.zeros((nexperiments,len(samplesizes)))\n",
    "\n",
    "    all_data_histos=[]\n",
    "    all_data_bins=[]\n",
    "\n",
    "    emlikelihoods=np.zeros((nexperiments,nrestarts,len(samplesizes)))\n",
    "\n",
    "\n",
    "    for ex in range(nexperiments):\n",
    "        print(\"****** Experiment {}\".format(ex))\n",
    "        ex_data_histos=[]\n",
    "        ex_data_bins=[]\n",
    "        for i,sz in enumerate(samplesizes):\n",
    "            print(\"***Sample size {}\".format(sz))\n",
    "            #initsize=int(sz/5)\n",
    "\n",
    "            if dim==1:\n",
    "                cd=sampling.sample(sz,mugen,Sigmagen,cparams,ctypes,binbounds=bbs)\n",
    "                print(\"Missing: {}%\".format(cd.percinc()))\n",
    "            if dim==2:    \n",
    "                cd=sampling.sample(sz,mugen,Sigmagen,cparams,ctypes)\n",
    "            # Save data histograms only in the 1d case for now:\n",
    "            if dim==1:\n",
    "                ex_data_histos.append(np.histogram(cd.data[0],bins=int(10*np.log(samplesizes[i])-30)))\n",
    "                ex_data_bins.append(cd.data[1:3])\n",
    "            datastats[ex,i,0:numparams]=np.vstack(cd.acameanvar(sz)).ravel()\n",
    "            datastats[ex,i,numparams]=cd.percinc()\n",
    "            for rs in range(nrestarts):\n",
    "                aca_initparams=cd.acameanvar(initsize)\n",
    "                tick=time.time()\n",
    "                #print(timestats_em)\n",
    "                emres=em.em(cd,initgauss=aca_initparams)\n",
    "                learnedparams_em[ex,rs,i,:]=np.vstack(emres).ravel() \n",
    "                emlikelihoods[ex,rs,i]= cd.carllikelihood(emres[0],emres[1]) \n",
    "                timestats_em[ex,i]+=time.time()-tick  \n",
    "                #print(timestats_em)\n",
    "\n",
    "                em_initparams=emres\n",
    "\n",
    "                \n",
    "                for j,nb in enumerate(granularities):         \n",
    "                    for initmode in [\"acainit\",\"eminit\"]:\n",
    "                        if initmode == \"acainit\":\n",
    "                            initparams=aca_initparams\n",
    "                        else:\n",
    "                            initparams=em_initparams\n",
    "                        tick=time.time()    \n",
    "                        result=aim.aim(cd,\\\n",
    "                                   initparams,\\\n",
    "                                   nbins=nb,\\\n",
    "                                   nticks=np.max((2,int(1000/nb))),\\\n",
    "                                   e=1.01, \\\n",
    "                                   maxits=50)\n",
    "                        \n",
    "                        binidx=j\n",
    "                        if  initmode==\"acainit\":       \n",
    "                            timestats_aim[ex,i,j]+=time.time()-tick\n",
    "                            learnedparams_aim[ex,rs,i,binidx,:]=np.vstack(result[1:3]).ravel()\n",
    "                            klvals_aim[ex,rs,i,binidx]=result[3] \n",
    "                        else:\n",
    "                            timestats_em_aim[ex,i,j]+=time.time()-tick\n",
    "                            learnedparams_em_aim[ex,rs,i,binidx,:]=np.vstack(result[1:3]).ravel()\n",
    "                            klvals_em_aim[ex,rs,i,binidx]=result[3] \n",
    "        if dim==1:            \n",
    "            all_data_histos.append(ex_data_histos)\n",
    "            all_data_bins.append(ex_data_bins)\n",
    "\n",
    "    savestuff={}\n",
    "    savestuff['readme']=readme\n",
    "    savestuff['dim']=dim\n",
    "    savestuff['numparams']=numparams\n",
    "    savestuff['mugen']=mugen\n",
    "    savestuff['Sigmagen']=Sigmagen\n",
    "    savestuff['restarts']=nrestarts\n",
    "    savestuff['nexperiments']=nexperiments\n",
    "    savestuff['samplesizes']=samplesizes\n",
    "    savestuff['granularities']=granularities\n",
    "    savestuff['initsize']=initsize\n",
    "    savestuff['cparams']=cparams\n",
    "    savestuff['ctypes']=ctypes\n",
    "    if dim==1:\n",
    "        savestuff['bbs']=bbs\n",
    "    savestuff['learnedparams AIM']= learnedparams_aim\n",
    "    savestuff['learnedparams EM-AIM']= learnedparams_em_aim\n",
    "    savestuff['learnedparams EM']= learnedparams_em\n",
    "    savestuff['KL_aim vals']= klvals_aim\n",
    "    savestuff['KL_em_aim vals']= klvals_em_aim\n",
    "    savestuff['EM likelihoods']=emlikelihoods\n",
    "    savestuff['datastats']=datastats\n",
    "    #savestuff['datasets']=datasets\n",
    "    savestuff['data_histos']=all_data_histos\n",
    "    savestuff['data_bins']=all_data_bins\n",
    "    savestuff['timestats_aim']=timestats_aim\n",
    "    savestuff['timestats_em']=timestats_em                      \n",
    "\n",
    "\n",
    "    pickle.dump( savestuff, open( \"./Results/\"+filename+\".pkl\" , \"wb\" ) )\n",
    "    return learnedparams_em,learnedparams_aim,learnedparams_em_aim,\\\n",
    "           klvals_aim,klvals_em_aim,emlikelihoods,timestats_aim,timestats_em,datastats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of experimental settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "allsettings=[]\n",
    "\n",
    "settings={}\n",
    "\n",
    "\"\"\"\n",
    "First the parameters of the underlying complete data model:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ### 1d:\n",
    "# settings['mugen']=np.array([0.5])\n",
    "# settings['Sigmagen']=np.array([1])\n",
    "\n",
    "### 2d:\n",
    "settings['mugen'] = np.array([0.5,0.5])\n",
    "settings['Sigmagen'] = np.array([[1,1],[1,2]])\n",
    "\n",
    "\"\"\"\n",
    "Specification of the coarsening probability function:\n",
    "\"\"\"\n",
    "\n",
    "### 1d:\n",
    "\n",
    "# # t1:\n",
    "# settings['cparams']=[[np.array([[-5.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # t2:         \n",
    "# settings['cparam]=[[np.array([[-3.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # t3:\n",
    "# settings['cparams']=[[np.array([[-1.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # t4:\n",
    "# settings['cparams']=[[np.array([[0.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # c1:\n",
    "# settings['cparams']=[[np.array([[12.0],[-0.8],[1.0]]),np.array([[12.0],[0.8],[1.0]])]]\n",
    "# settings['ctypes']=[['central','central']]\n",
    "# # c2:\n",
    "# settings['cparams']=[[np.array([[2.0],[-0.8],[0.5]]),np.array([[2.0],[0.8],[0.5]])]]\n",
    "# settings['ctypes']=[['central','central']]\n",
    "\n",
    "\n",
    "### 2d:\n",
    "\n",
    "### c1,t1:\n",
    "d0params=[np.array([[12.0],[-0.8],[1.0]]),np.array([[12.0],[0.8],[1.0]])]\n",
    "d1params=[np.array([[-5.0],[-0.5],[0.9]])]\n",
    "settings['cparams']=[d0params,d1params]\n",
    "settings['ctypes']=[['central','central'],['tail']]\n",
    "# ### c2,t4:\n",
    "# d0params=[np.array([[2.0],[-0.8],[1.0]]),np.array([[2.0],[0.8],[1.0]])]\n",
    "# d1params=[np.array([[0.0],[-0.5],[0.9]])]\n",
    "# settings['cparams']=[d0params,d1params]\n",
    "# settings['ctypes']=[['central','central'],['tail']]\n",
    "\n",
    "\"\"\"\n",
    "For the 1d-b case: define the bins:\n",
    "\"\"\"\n",
    "\n",
    "# # # settings['bbs']=np.array([]) # B_1\n",
    "# settings['bbs']=np.array([-1,1]) # B_2\n",
    "\n",
    "\n",
    "\n",
    "# Number of experimental runs:\n",
    "settings['nexperiments']=2\n",
    "# Number of restarts in every run:\n",
    "settings['nrestarts']=5\n",
    "# Different sample sizes to use:\n",
    "settings['samplesizes']=[100,1000]\n",
    "# granularities: \n",
    "settings['granularities']=[3]\n",
    "\n",
    "\n",
    "allsettings.append(settings)\n",
    "\n",
    "\n",
    "'''\n",
    "Add a second setting, e.g. modifying the number of restarts:\n",
    "'''\n",
    "# settings=settings.copy()\n",
    "# settings['nrestarts']=20\n",
    "# allsettings.append(settings)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run experiments under all settings. For each of the settings a separate result file will be generated. The  aim learner will generate some outputs that may include warning messages about negative KL values or similar. These warnings are due to numerical underflow problems that occur locally in the computations, and usually do not indicate serious problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for settings in allsettings:\n",
    "    \n",
    "    print(\"Running experiment with settings: \\n {}\".format(settings))\n",
    "    learnedparams_em,learnedparams_aim,learnedparams_em_aim,\\\n",
    "           klvals_aim,klvals_em_aim,emlikelihoods,timestats_aim,timestats_em,datastats=runexperiment(settings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results from the file saved for this experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='1d-tail-2021-07-22 17:12:56.909521.pkl'\n",
    "\n",
    "retrieve=pickle.load( open( \"./Results/\" + datafile, \"rb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Keys: {} \\n\".format(retrieve.keys()))\n",
    "print(\"Readme: {}\".format(retrieve['readme']))\n",
    "\n",
    "mugen=retrieve['mugen']\n",
    "Sigmagen=retrieve['Sigmagen']\n",
    "dim=retrieve['dim']\n",
    "numparams=retrieve['numparams']\n",
    "learnedparams_aim=retrieve['learnedparams AIM']\n",
    "learnedparams_em_aim=retrieve['learnedparams EM-AIM']\n",
    "learnedparams_em=retrieve['learnedparams EM']\n",
    "klvals_aim=retrieve['KL_aim vals']\n",
    "klvals_em_aim=retrieve['KL_em_aim vals']\n",
    "emlikelihoods=retrieve['EM likelihoods']\n",
    "datastats=retrieve['datastats']\n",
    "nrestarts=retrieve['restarts']\n",
    "granularities=retrieve['granularities']\n",
    "all_data_histos=retrieve['data_histos']\n",
    "all_data_bins=retrieve['data_bins']\n",
    "samplesizes=retrieve['samplesizes']\n",
    "nexperiments=retrieve['nexperiments']\n",
    "timestats_aim=retrieve['timestats_aim']\n",
    "timestats_em=retrieve['timestats_em']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate several summaries and evaluations of the experimental results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true = np.vstack((mugen,Sigmagen)).ravel()\n",
    "idx=-1\n",
    "\n",
    "# Computing several summaries and final results:\n",
    "\n",
    "######\n",
    "# For AIM evaluation:\n",
    "######\n",
    "varlearnedparams_aim=np.var(learnedparams_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities),numparams) \n",
    "totalvar_aim=np.sum(varlearnedparams_aim,axis=3) #shape: (nexperiments,len(samplesizes),len(granularities)) \n",
    "minkl_aim=np.min(klvals_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities))\n",
    "\n",
    "totalvar_aim_max=np.max(totalvar_aim,axis=2)\n",
    "totalvar_aim_min=np.min(totalvar_aim,axis=2)\n",
    "totalvar_aim_range=totalvar_aim_max-totalvar_aim_min\n",
    "totalvar_aim_normalized=(totalvar_aim-totalvar_aim_min[:,:,np.newaxis])/totalvar_aim_range[:,:,np.newaxis]\n",
    "\n",
    "minkl_aim_max=np.max(minkl_aim,axis=2)\n",
    "minkl_aim_min=np.min(minkl_aim,axis=2)\n",
    "minkl_aim_range=minkl_aim_max-minkl_aim_min\n",
    "minkl_aim_normalized=(minkl_aim-minkl_aim_min[:,:,np.newaxis])/minkl_aim_range[:,:,np.newaxis]\n",
    "\n",
    "optbinidx_aim=np.argmin(totalvar_aim_normalized+minkl_aim_normalized,axis=2)\n",
    "optbinvals_aim=np.zeros((nexperiments,len(samplesizes)))\n",
    "for e in range(nexperiments):\n",
    "    for s in range(len(samplesizes)):\n",
    "        optbinvals_aim[e,s]=granularities[optbinidx_aim[e,s]]\n",
    "\n",
    "\n",
    "######\n",
    "# For EM-AIM evaluation:\n",
    "######\n",
    "varlearnedparams_em_aim=np.var(learnedparams_em_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities),numparams) \n",
    "totalvar_em_aim=np.sum(varlearnedparams_em_aim,axis=3) #shape: (nexperiments,len(samplesizes),len(granularities)) \n",
    "minkl_em_aim=np.min(klvals_em_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities))\n",
    "\n",
    "totalvar_em_aim_max=np.max(totalvar_em_aim,axis=2)\n",
    "totalvar_em_aim_min=np.min(totalvar_em_aim,axis=2)\n",
    "totalvar_em_aim_range=totalvar_aim_max-totalvar_em_aim_min\n",
    "totalvar_em_aim_normalized=\\\n",
    "(totalvar_em_aim-totalvar_em_aim_min[:,:,np.newaxis])/totalvar_em_aim_range[:,:,np.newaxis]\n",
    "\n",
    "minkl_em_aim_max=np.max(minkl_em_aim,axis=2)\n",
    "minkl_em_aim_min=np.min(minkl_em_aim,axis=2)\n",
    "minkl_em_aim_range=minkl_em_aim_max-minkl_em_aim_min\n",
    "minkl_em_aim_normalized=(minkl_em_aim-minkl_em_aim_min[:,:,np.newaxis])/minkl_em_aim_range[:,:,np.newaxis]\n",
    "\n",
    "optbinidx_em_aim=np.argmin(totalvar_em_aim_normalized+minkl_em_aim_normalized,axis=2)\n",
    "optbinvals_em_aim=np.zeros((nexperiments,len(samplesizes)))\n",
    "for e in range(nexperiments):\n",
    "    for s in range(len(samplesizes)):\n",
    "        optbinvals_em_aim[e,s]=granularities[optbinidx_em_aim[e,s]]\n",
    "        \n",
    "        \n",
    "######\n",
    "# Collecting all learned parameters:\n",
    "######       \n",
    "\n",
    "\n",
    "numbins=len(granularities)\n",
    "    \n",
    "bestparams_aim=np.zeros((nexperiments,len(samplesizes),numbins,numparams)) \n",
    "averageparams_aim=np.zeros((nexperiments,len(samplesizes),numbins,numparams)) \n",
    "bestparams_em_aim=np.zeros((nexperiments,len(samplesizes),numbins,numparams)) \n",
    "bestparams_em=np.zeros((nexperiments,len(samplesizes),numparams))\n",
    "\n",
    "for ex in range(nexperiments):\n",
    "    for i in range(len(samplesizes)):\n",
    "        for bs in range(numbins):\n",
    "            bestparams_aim[ex,i,bs,:]=learnedparams_aim[ex,np.argmin(klvals_aim[ex,:,i,bs]),i,bs,:]  \n",
    "            bestparams_em_aim[ex,i,bs,:]=learnedparams_em_aim[ex,np.argmin(klvals_em_aim[ex,:,i,bs]),i,bs,:] \n",
    "            averageparams_aim[ex,i,bs,:]=np.average(learnedparams_aim[ex,:,i,bs,:],axis=0)\n",
    "        ropt=np.argmin(emlikelihoods[ex,:,i])\n",
    "        bestparams_em[ex,i,:]=learnedparams_em[ex,ropt,i,:]\n",
    "\n",
    "##########\n",
    "# Evaluating against ground truth:\n",
    "##########\n",
    "        \n",
    "score_all_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),numbins))\n",
    "score_best_aim=np.zeros((nexperiments,len(samplesizes),numbins))\n",
    "score_best_aim_optbin=np.zeros((nexperiments,len(samplesizes)))\n",
    "score_average_aim=np.zeros((nexperiments,len(samplesizes),numbins))\n",
    "\n",
    "\n",
    "score_all_em_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),numbins))\n",
    "score_best_em_aim=np.zeros((nexperiments,len(samplesizes),numbins))\n",
    "score_best_em_aim_optbin=np.zeros((nexperiments,len(samplesizes)))\n",
    "\n",
    "score_best_em=np.zeros((nexperiments,len(samplesizes)))\n",
    "score_aca=np.zeros((nexperiments,len(samplesizes)))\n",
    "\n",
    "#datastats[ex,i,0:numparams]=np.vstack(cd.acameanvar(sz)).ravel()\n",
    "\n",
    "for ex in range(nexperiments):\n",
    "    for i in range(len(samplesizes)):\n",
    "        score_best_em[ex,i]=aim.score(true,bestparams_em[ex,i,:],idx)\n",
    "        score_aca[ex,i]=aim.score(true, datastats[ex,i,0:numparams],idx)\n",
    "        score_best_aim_optbin[ex,i]=aim.score(true,bestparams_aim[ex,i,optbinidx_aim[ex,i],:],idx)\n",
    "        score_best_em_aim_optbin[ex,i]=aim.score(true,bestparams_em_aim[ex,i,optbinidx_em_aim[ex,i],:],idx)\n",
    "        for bs in range(numbins):\n",
    "            for rs in range(nrestarts):\n",
    "                score_all_aim[ex,rs,i,bs]=aim.score(true,learnedparams_aim[ex,rs,i,bs],idx)   \n",
    "                score_all_em_aim[ex,rs,i,bs]=aim.score(true,learnedparams_em_aim[ex,rs,i,bs],idx) \n",
    "            score_best_aim[ex,i,bs]=score_all_aim[ex,np.argmin(klvals_aim[ex,:,i,bs]),i,bs]\n",
    "            score_average_aim[ex,i,bs]=aim.score(true,averageparams_aim[ex,i,bs,:],-1)\n",
    "            score_best_em_aim[ex,i,bs]=score_all_em_aim[ex,np.argmin(klvals_em_aim[ex,:,i,bs]),i,bs]\n",
    "            \n",
    "#####\n",
    "# For time stats:\n",
    "#####\n",
    "\n",
    "time_aim=np.sum(timestats_aim,axis=2) # summing over the granularities; shape: (nexperiments,len(samplesizes))\n",
    "                                      # same as timestats_em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jitter=0.03\n",
    "\n",
    "legends=[]\n",
    "\n",
    "for b in range(len(granularities)):\n",
    "    legends.append(granularities[b])\n",
    "    \n",
    "\n",
    "#figure=plt.figure(figsize=(15,10)) \n",
    "figure=plt.figure(figsize=(12,8)) \n",
    "ax = figure.add_subplot(111)\n",
    "\n",
    "#mpl.rcParams['axes.labelsize']=20\n",
    "\n",
    "# #Individual bin sizes AIM:    \n",
    "# for bs in range(numbins):\n",
    "#     y=np.average(score_best_aim[:,:,bs],axis=0)\n",
    "#     yerr=np.std(score_best_aim[:,:,bs],axis=0)\n",
    "#     plt.errorbar((1+jitter*bs)*np.array(samplesizes),y,yerr,label=legends[bs])\n",
    "    \n",
    "#     y=np.average(score_average_aim[:,:,bs],axis=0)\n",
    "#     yerr=np.std(score_average_aim[:,:,bs],axis=0)\n",
    "#     plt.errorbar((1+jitter*bs)*np.array(samplesizes),y,yerr,label=\"avg\"+str(legends[bs]))\n",
    "    \n",
    "#ACA:\n",
    "y=np.average(score_aca[:,:],axis=0)\n",
    "yerr=np.std(score_aca[:,:],axis=0)\n",
    "ax.errorbar((1-2*jitter)*np.array(samplesizes),y,yerr,c='green',label='ACA')\n",
    "\n",
    "#EM:    \n",
    "y=np.average(score_best_em[:,:],axis=0)\n",
    "yerr=np.std(score_best_em[:,:],axis=0)\n",
    "ax.errorbar((1-jitter)*np.array(samplesizes),y,yerr,c='mediumblue',label='EM')\n",
    "\n",
    "\n",
    "    \n",
    "#Best binsize AIM:\n",
    "y=np.average(score_best_aim_optbin[:,:],axis=0)\n",
    "yerr=np.std(score_best_aim_optbin[:,:],axis=0)\n",
    "ax.errorbar((1-3*jitter)*np.array(samplesizes),y,yerr,c='red', label='AIM')\n",
    "#Best binsize EM-AIM:\n",
    "y=np.average(score_best_em_aim_optbin[:,:],axis=0)\n",
    "yerr=np.std(score_best_em_aim_optbin[:,:],axis=0)\n",
    "ax.errorbar((1-4*jitter)*np.array(samplesizes),y,yerr,c='darkviolet',label='EM-AIM')\n",
    "\n",
    "\n",
    "#Binsize:\n",
    "axright=ax.twinx()\n",
    "\n",
    "y=np.average(optbinvals_aim[:,:],axis=0)\n",
    "yerr=np.std(optbinvals_aim[:,:],axis=0)\n",
    "axright.errorbar(np.array(samplesizes),y,yerr,c='dimgray',label='# cells (AIM)')\n",
    "\n",
    "y=np.average(optbinvals_em_aim[:,:],axis=0)\n",
    "yerr=np.std(optbinvals_em_aim[:,:],axis=0)\n",
    "axright.errorbar((1+jitter)*np.array(samplesizes),y,yerr,c='lightgray',label='# cells (EM-AIM)')\n",
    "\n",
    "# Construct the legend\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "linesr, labelsr = axright.get_legend_handles_labels()\n",
    "#axright.legend(lines + linesr, labels + labelsr) # use this for local legend inside plot\n",
    "# axright.legend(lines + linesr, labels + labelsr,loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "#          ncol=6, fontsize=15, fancybox=True, shadow=True) # use this for separate legend outside\n",
    "\n",
    "\n",
    "# ax.set_ylabel(\"squared error\", fontsize=20)\n",
    "# axright.set_ylabel(\"# cells\", fontsize=20)\n",
    "# ax.set_xlabel(\"sample size\", fontsize=20)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=25)\n",
    "ax.yaxis.set_tick_params(labelsize=25)\n",
    "axright.yaxis.set_tick_params(labelsize=25)\n",
    "#ax.set_ylim((0,0.2))\n",
    "#plt.legend()    \n",
    "plt.show()         \n",
    "\n",
    "print(retrieve['readme'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
