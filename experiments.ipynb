{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm,multivariate_normal\n",
    "from numpy.random import random\n",
    "from math import nan\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import utils as utl\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import aim,em,sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that runs a full experiment according to given experimental settings. Results are returned and saved in a file in the ./Results directory (should exist!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runexperiment(settings):\n",
    "    mugen=settings['mugen']\n",
    "    Sigmagen=settings['Sigmagen']\n",
    "    nexperiments=settings['nexperiments']\n",
    "    nrestarts=settings['nrestarts']\n",
    "    cparams=settings['cparams']\n",
    "    ctypes=settings['ctypes']\n",
    "    \n",
    "    samplesizes=settings['samplesizes']\n",
    "    granularities=settings['granularities']\n",
    "    dim=len(cparams)\n",
    "    initsize=20\n",
    "\n",
    " \n",
    "    timestamp = str(datetime.now())\n",
    "\n",
    "    typestr =\"\"\n",
    "    for tstr in ctypes:\n",
    "        for ttstr in tstr:\n",
    "            typestr+=\"-\"+ttstr\n",
    "        \n",
    "    filename= str(dim)+\"d\" + typestr +\"-\"+timestamp\n",
    "\n",
    "    readme = timestamp + \"\\n\"\n",
    "    readme +=str(dim)+'d with {} coarsening with parameters {}\\n'.format(ctypes,cparams)\n",
    "    if dim==1:\n",
    "        bbs=settings['bbs']\n",
    "        readme +=\"Coarsening bin bounds: {} \\n\".format(bbs)\n",
    "    readme +='Samplesizes: {}\\n'.format(samplesizes)\n",
    "    readme +='Granularities: {}\\n'.format(granularities) \n",
    "    readme +='Restarts: {}\\n'.format(nrestarts) \n",
    "    readme +='Experiments: {}\\n'.format(nexperiments) \n",
    "    readme +='ACA initsize: {}\\n'.format(initsize)\n",
    "\n",
    "\n",
    "\n",
    "    if dim==1:\n",
    "        numparams=2 #mu,Sigma\n",
    "        \n",
    "    if dim==2:\n",
    "        numparams=6 # mu[0],mu[1],Sigma[0,0],Sigma[0,1],Sigma[1,0],Sigma[1,1]\n",
    "\n",
    "   \n",
    "    actualnumbins=len(granularities)\n",
    "\n",
    "    learnedparams_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins,numparams))\n",
    "    klvals_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins))\n",
    "\n",
    "    learnedparams_em_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins,numparams))\n",
    "    klvals_em_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),actualnumbins))\n",
    "\n",
    "    learnedparams_em=np.zeros((nexperiments,nrestarts,len(samplesizes),numparams))\n",
    "    datastats=np.zeros((nexperiments,len(samplesizes),numparams+1)) # aca parameter estimates, missing %\n",
    "    timestats_aim=np.zeros((nexperiments,len(samplesizes),len(granularities)))\n",
    "    timestats_em_aim=np.zeros((nexperiments,len(samplesizes),len(granularities)))\n",
    "    timestats_em=np.zeros((nexperiments,len(samplesizes)))\n",
    "\n",
    "    all_data_histos=[]\n",
    "    all_data_bins=[]\n",
    "\n",
    "    emlikelihoods=np.zeros((nexperiments,nrestarts,len(samplesizes)))\n",
    "\n",
    "\n",
    "    for ex in range(nexperiments):\n",
    "        print(\"****** Experiment {}\".format(ex))\n",
    "        ex_data_histos=[]\n",
    "        ex_data_bins=[]\n",
    "        for i,sz in enumerate(samplesizes):\n",
    "            print(\"***Sample size {}\".format(sz))\n",
    "            #initsize=int(sz/5)\n",
    "\n",
    "            if dim==1:\n",
    "                cd=sampling.sample(sz,mugen,Sigmagen,cparams,ctypes,binbounds=bbs)\n",
    "                print(\"Missing: {}%\".format(cd.percinc()))\n",
    "            if dim==2:    \n",
    "                cd=sampling.sample(sz,mugen,Sigmagen,cparams,ctypes)\n",
    "            # Save data histograms only in the 1d case for now:\n",
    "            if dim==1:\n",
    "                ex_data_histos.append(np.histogram(cd.data[0],bins=int(10*np.log(samplesizes[i])-30)))\n",
    "                ex_data_bins.append(cd.data[1:3])\n",
    "            datastats[ex,i,0:numparams]=np.vstack(cd.acameanvar(sz)).ravel()\n",
    "            datastats[ex,i,numparams]=cd.percinc()\n",
    "            for rs in range(nrestarts):\n",
    "                aca_initparams=cd.acameanvar(initsize)\n",
    "                tick=time.time()\n",
    "                #print(timestats_em)\n",
    "                emres=em.em(cd,initgauss=aca_initparams)\n",
    "                learnedparams_em[ex,rs,i,:]=np.vstack(emres).ravel() \n",
    "                emlikelihoods[ex,rs,i]= cd.carllikelihood(emres[0],emres[1]) \n",
    "                timestats_em[ex,i]+=time.time()-tick  \n",
    "                #print(timestats_em)\n",
    "\n",
    "                em_initparams=emres\n",
    "\n",
    "                \n",
    "                for j,nb in enumerate(granularities):         \n",
    "                    for initmode in [\"acainit\",\"eminit\"]:\n",
    "                        if initmode == \"acainit\":\n",
    "                            initparams=aca_initparams\n",
    "                        else:\n",
    "                            initparams=em_initparams\n",
    "                        tick=time.time()    \n",
    "                        result=aim.aim(cd,\\\n",
    "                                   initparams,\\\n",
    "                                   nbins=nb,\\\n",
    "                                   nticks=np.max((2,int(1000/nb))),\\\n",
    "                                   e=1.01, \\\n",
    "                                   maxits=50)\n",
    "                        \n",
    "                        binidx=j\n",
    "                        if  initmode==\"acainit\":       \n",
    "                            timestats_aim[ex,i,j]+=time.time()-tick\n",
    "                            learnedparams_aim[ex,rs,i,binidx,:]=np.vstack(result[1:3]).ravel()\n",
    "                            klvals_aim[ex,rs,i,binidx]=result[3] \n",
    "                        else:\n",
    "                            timestats_em_aim[ex,i,j]+=time.time()-tick\n",
    "                            learnedparams_em_aim[ex,rs,i,binidx,:]=np.vstack(result[1:3]).ravel()\n",
    "                            klvals_em_aim[ex,rs,i,binidx]=result[3] \n",
    "        if dim==1:            \n",
    "            all_data_histos.append(ex_data_histos)\n",
    "            all_data_bins.append(ex_data_bins)\n",
    "\n",
    "    savestuff={}\n",
    "    savestuff['readme']=readme\n",
    "    savestuff['dim']=dim\n",
    "    savestuff['numparams']=numparams\n",
    "    savestuff['mugen']=mugen\n",
    "    savestuff['Sigmagen']=Sigmagen\n",
    "    savestuff['restarts']=nrestarts\n",
    "    savestuff['nexperiments']=nexperiments\n",
    "    savestuff['samplesizes']=samplesizes\n",
    "    savestuff['granularities']=granularities\n",
    "    savestuff['initsize']=initsize\n",
    "    savestuff['cparams']=cparams\n",
    "    savestuff['ctypes']=ctypes\n",
    "    if dim==1:\n",
    "        savestuff['bbs']=bbs\n",
    "    savestuff['learnedparams AIM']= learnedparams_aim\n",
    "    savestuff['learnedparams EM-AIM']= learnedparams_em_aim\n",
    "    savestuff['learnedparams EM']= learnedparams_em\n",
    "    savestuff['KL_aim vals']= klvals_aim\n",
    "    savestuff['KL_em_aim vals']= klvals_em_aim\n",
    "    savestuff['EM likelihoods']=emlikelihoods\n",
    "    savestuff['datastats']=datastats\n",
    "    #savestuff['datasets']=datasets\n",
    "    savestuff['data_histos']=all_data_histos\n",
    "    savestuff['data_bins']=all_data_bins\n",
    "    savestuff['timestats_aim']=timestats_aim\n",
    "    savestuff['timestats_em']=timestats_em                      \n",
    "\n",
    "\n",
    "    pickle.dump( savestuff, open( \"./Results/\"+filename+\".pkl\" , \"wb\" ) )\n",
    "    return learnedparams_em,learnedparams_aim,learnedparams_em_aim,\\\n",
    "           klvals_aim,klvals_em_aim,emlikelihoods,timestats_aim,timestats_em,datastats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of experimental settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdd a second setting, e.g. modifying the number of restarts:\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "allsettings=[]\n",
    "\n",
    "settings={}\n",
    "\n",
    "\"\"\"\n",
    "First the parameters of the underlying complete data model:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ### 1d:\n",
    "# settings['mugen']=np.array([0.5])\n",
    "# settings['Sigmagen']=np.array([1])\n",
    "\n",
    "### 2d:\n",
    "settings['mugen'] = np.array([0.5,0.5])\n",
    "settings['Sigmagen'] = np.array([[1,1],[1,2]])\n",
    "\n",
    "\"\"\"\n",
    "Specification of the coarsening probability function:\n",
    "\"\"\"\n",
    "\n",
    "### 1d:\n",
    "\n",
    "# # t1:\n",
    "# settings['cparams']=[[np.array([[-5.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # t2:         \n",
    "# settings['cparam]=[[np.array([[-3.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # t3:\n",
    "# settings['cparams']=[[np.array([[-1.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # t4:\n",
    "# settings['cparams']=[[np.array([[0.0],[-0.5],[0.9]])]]\n",
    "# settings['ctypes']=[['tail']]         \n",
    "# # c1:\n",
    "# settings['cparams']=[[np.array([[12.0],[-0.8],[1.0]]),np.array([[12.0],[0.8],[1.0]])]]\n",
    "# settings['ctypes']=[['central','central']]\n",
    "# # c2:\n",
    "# settings['cparams']=[[np.array([[2.0],[-0.8],[0.5]]),np.array([[2.0],[0.8],[0.5]])]]\n",
    "# settings['ctypes']=[['central','central']]\n",
    "\n",
    "\n",
    "### 2d:\n",
    "\n",
    "### c1,t1:\n",
    "d0params=[np.array([[12.0],[-0.8],[1.0]]),np.array([[12.0],[0.8],[1.0]])]\n",
    "d1params=[np.array([[-5.0],[-0.5],[0.9]])]\n",
    "settings['cparams']=[d0params,d1params]\n",
    "settings['ctypes']=[['central','central'],['tail']]\n",
    "# ### c2,t4:\n",
    "# d0params=[np.array([[2.0],[-0.8],[1.0]]),np.array([[2.0],[0.8],[1.0]])]\n",
    "# d1params=[np.array([[0.0],[-0.5],[0.9]])]\n",
    "# settings['cparams']=[d0params,d1params]\n",
    "# settings['ctypes']=[['central','central'],['tail']]\n",
    "\n",
    "\"\"\"\n",
    "For the 1d-b case: define the bins:\n",
    "\"\"\"\n",
    "\n",
    "# # # settings['bbs']=np.array([]) # B_1\n",
    "# settings['bbs']=np.array([-1,1]) # B_2\n",
    "\n",
    "\n",
    "\n",
    "# Number of experimental runs:\n",
    "settings['nexperiments']=2\n",
    "# Number of restarts in every run:\n",
    "settings['nrestarts']=5\n",
    "# Different sample sizes to use:\n",
    "settings['samplesizes']=[100,1000]\n",
    "# granularities: \n",
    "settings['granularities']=[3]\n",
    "\n",
    "\n",
    "allsettings.append(settings)\n",
    "\n",
    "\n",
    "'''\n",
    "Add a second setting, e.g. modifying the number of restarts:\n",
    "'''\n",
    "# settings=settings.copy()\n",
    "# settings['nrestarts']=20\n",
    "# allsettings.append(settings)\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run experiments under all settings. For each of the settings a separate result file will be generated. The  aim learner will generate some outputs that may include warning messages about negative KL values or similar. These warnings are due to numerical underflow problems that occur locally in the computations, and usually do not indicate serious problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with settings: \n",
      " {'mugen': array([0.5, 0.5]), 'Sigmagen': array([[1, 1],\n",
      "       [1, 2]]), 'cparams': [[array([[12. ],\n",
      "       [-0.8],\n",
      "       [ 1. ]]), array([[12. ],\n",
      "       [ 0.8],\n",
      "       [ 1. ]])], [array([[-5. ],\n",
      "       [-0.5],\n",
      "       [ 0.9]])]], 'ctypes': [['central', 'central'], ['tail']], 'nexperiments': 2, 'nrestarts': 5, 'samplesizes': [100, 1000], 'granularities': [3]}\n",
      "****** Experiment 0\n",
      "***Sample size 100\n",
      "EM iterations: 6\n",
      "bins: 3 its: 24  Time AI: 0.04228496551513672   Time M: 2.827996253967285  Percentage M: 0.9852680060657047\n",
      "bins: 3 its: 50  Time AI: 0.07958436012268066   Time M: 5.686858415603638  Percentage M: 0.9861987080739466\n",
      "EM iterations: 5\n",
      "bins: 3 its: 14  Time AI: 0.02312612533569336   Time M: 1.6299958229064941  Percentage M: 0.9860106355975226\n",
      "bins: 3 its: 50  Time AI: 0.07921528816223145   Time M: 5.7227678298950195  Percentage M: 0.9863468599355808\n",
      "EM iterations: 5\n",
      "bins: 3 its: 50  Time AI: 0.0794980525970459   Time M: 5.670250654220581  Percentage M: 0.9861736474669262\n",
      "bins: 3 its: 50  Time AI: 0.07764410972595215   Time M: 5.686921119689941  Percentage M: 0.9865307951882054\n",
      "EM iterations: 7\n",
      "bins: 3 its: 50  Time AI: 0.07341909408569336   Time M: 5.80160117149353  Percentage M: 0.9875031760288822\n",
      "bins: 3 its: 50  Time AI: 0.0833430290222168   Time M: 5.995280981063843  Percentage M: 0.9862891620070713\n",
      "EM iterations: 5\n",
      "bins: 3 its: 30  Time AI: 0.04424452781677246   Time M: 3.81160306930542  Percentage M: 0.9885253432086386\n",
      "bins: 3 its: 50  Time AI: 0.08070945739746094   Time M: 6.070962429046631  Percentage M: 0.9868800776622509\n",
      "***Sample size 1000\n",
      "EM iterations: 4\n",
      "bins: 3 its: 50  Time AI: 0.08138847351074219   Time M: 6.035436391830444  Percentage M: 0.9866943266641651\n",
      "bins: 3 its: 50  Time AI: 0.07426285743713379   Time M: 6.491659641265869  Percentage M: 0.9886896536698684\n",
      "EM iterations: 5\n",
      "bins: 3 its: 36  Time AI: 0.07987451553344727   Time M: 4.524766683578491  Percentage M: 0.9826534767684283\n",
      "bins: 3 its: 50  Time AI: 0.07440876960754395   Time M: 6.4200279712677  Percentage M: 0.988542690832721\n",
      "EM iterations: 5\n",
      "bins: 3 its: 49  Time AI: 0.07700681686401367   Time M: 6.120101690292358  Percentage M: 0.9875737504394047\n",
      "bins: 3 its: 50  Time AI: 0.07140588760375977   Time M: 6.289703369140625  Percentage M: 0.9887746170169847\n",
      "EM iterations: 5\n",
      "bins: 3 its: 50  Time AI: 0.1158905029296875   Time M: 6.272768497467041  Percentage M: 0.9818599642080613\n",
      "bins: 3 its: 50  Time AI: 0.07220458984375   Time M: 6.302302598953247  Percentage M: 0.9886729142025837\n",
      "EM iterations: 4\n",
      "bins: 3 its: 32  Time AI: 0.06656813621520996   Time M: 4.100006103515625  Percentage M: 0.9840232929056101\n",
      "bins: 3 its: 50  Time AI: 0.07143688201904297   Time M: 6.172681093215942  Percentage M: 0.9885593317899548\n",
      "****** Experiment 1\n",
      "***Sample size 100\n",
      "EM iterations: 7\n",
      "bins: 3 its: 11  Time AI: 0.01804351806640625   Time M: 1.3948440551757812  Percentage M: 0.9872293320373671\n",
      "bins: 3 its: 18  Time AI: 0.022488117218017578   Time M: 2.272249460220337  Percentage M: 0.9902001355452934\n",
      "EM iterations: 4\n",
      "bins: 3 its: 24  Time AI: 0.02875375747680664   Time M: 3.112900495529175  Percentage M: 0.9908475741882499\n",
      "bins: 3 its: 18  Time AI: 0.02239704132080078   Time M: 2.2993547916412354  Percentage M: 0.9903533870404111\n",
      "EM iterations: 5\n",
      "bins: 3 its: 23  Time AI: 0.026877403259277344   Time M: 2.957797050476074  Percentage M: 0.9909948626974576\n",
      "bins: 3 its: 18  Time AI: 0.022799253463745117   Time M: 2.3122193813323975  Percentage M: 0.9902359436777105\n",
      "EM iterations: 5\n",
      "bins: 3 its: 14  Time AI: 0.014720678329467773   Time M: 1.8640921115875244  Percentage M: 0.9921649041306994\n",
      "bins: 3 its: 18  Time AI: 0.02289867401123047   Time M: 2.286616802215576  Percentage M: 0.9900850744465929\n",
      "EM iterations: 6\n",
      "bins: 3 its: 18  Time AI: 0.024983644485473633   Time M: 2.1900932788848877  Percentage M: 0.9887210939620735\n",
      "bins: 3 its: 18  Time AI: 0.022240638732910156   Time M: 2.2399139404296875  Percentage M: 0.9901683824183477\n",
      "***Sample size 1000\n",
      "EM iterations: 4\n",
      "bins: 3 its: 50  Time AI: 0.12028670310974121   Time M: 6.392979860305786  Percentage M: 0.9815320466407161\n",
      "bins: 3 its: 22  Time AI: 0.04484724998474121   Time M: 2.8587749004364014  Percentage M: 0.9845547224599328\n",
      "EM iterations: 4\n",
      "bins: 3 its: 42  Time AI: 0.08590364456176758   Time M: 5.372848272323608  Percentage M: 0.9842631345278681\n",
      "bins: 3 its: 24  Time AI: 0.04752826690673828   Time M: 3.1010289192199707  Percentage M: 0.9849047471279356\n",
      "EM iterations: 4\n",
      "bins: 3 its: 36  Time AI: 0.0755610466003418   Time M: 4.62323522567749  Percentage M: 0.9839190630489472\n",
      "bins: 3 its: 22  Time AI: 0.03959488868713379   Time M: 2.7168617248535156  Percentage M: 0.9856355842886733\n",
      "EM iterations: 5\n",
      "bins: 3 its: 42  Time AI: 0.09290242195129395   Time M: 5.05944299697876  Percentage M: 0.9819689065080993\n",
      "bins: 3 its: 24  Time AI: 0.04502415657043457   Time M: 2.927727222442627  Percentage M: 0.9848543820757112\n",
      "EM iterations: 4\n",
      "bins: 3 its: 50  Time AI: 0.11279845237731934   Time M: 6.125596761703491  Percentage M: 0.9819186748343998\n",
      "bins: 3 its: 22  Time AI: 0.04142332077026367   Time M: 2.7166693210601807  Percentage M: 0.9849811713566037\n"
     ]
    }
   ],
   "source": [
    "for settings in allsettings:\n",
    "    \n",
    "    print(\"Running experiment with settings: \\n {}\".format(settings))\n",
    "    learnedparams_em,learnedparams_aim,learnedparams_em_aim,\\\n",
    "           klvals_aim,klvals_em_aim,emlikelihoods,timestats_aim,timestats_em,datastats=runexperiment(settings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(settings['cparams']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results from the file saved for this experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile='1d-tail-2021-07-22 17:12:56.909521.pkl'\n",
    "\n",
    "retrieve=pickle.load( open( \"./Results/\" + datafile, \"rb\" ) )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Keys: {} \\n\".format(retrieve.keys()))\n",
    "print(\"Readme: {}\".format(retrieve['readme']))\n",
    "\n",
    "mugen=retrieve['mugen']\n",
    "Sigmagen=retrieve['Sigmagen']\n",
    "dim=retrieve['dim']\n",
    "numparams=retrieve['numparams']\n",
    "learnedparams_aim=retrieve['learnedparams AIM']\n",
    "learnedparams_em_aim=retrieve['learnedparams EM-AIM']\n",
    "learnedparams_em=retrieve['learnedparams EM']\n",
    "klvals_aim=retrieve['KL_aim vals']\n",
    "klvals_em_aim=retrieve['KL_em_aim vals']\n",
    "emlikelihoods=retrieve['EM likelihoods']\n",
    "datastats=retrieve['datastats']\n",
    "nrestarts=retrieve['restarts']\n",
    "granularities=retrieve['granularities']\n",
    "all_data_histos=retrieve['data_histos']\n",
    "all_data_bins=retrieve['data_bins']\n",
    "samplesizes=retrieve['samplesizes']\n",
    "nexperiments=retrieve['nexperiments']\n",
    "timestats_aim=retrieve['timestats_aim']\n",
    "timestats_em=retrieve['timestats_em']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate several summaries and evaluations of the experimental results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true = np.vstack((mugen,Sigmagen)).ravel()\n",
    "idx=-1\n",
    "\n",
    "# Computing several summaries and final results:\n",
    "\n",
    "######\n",
    "# For AIM evaluation:\n",
    "######\n",
    "varlearnedparams_aim=np.var(learnedparams_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities),numparams) \n",
    "totalvar_aim=np.sum(varlearnedparams_aim,axis=3) #shape: (nexperiments,len(samplesizes),len(granularities)) \n",
    "minkl_aim=np.min(klvals_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities))\n",
    "\n",
    "totalvar_aim_max=np.max(totalvar_aim,axis=2)\n",
    "totalvar_aim_min=np.min(totalvar_aim,axis=2)\n",
    "totalvar_aim_range=totalvar_aim_max-totalvar_aim_min\n",
    "totalvar_aim_normalized=(totalvar_aim-totalvar_aim_min[:,:,np.newaxis])/totalvar_aim_range[:,:,np.newaxis]\n",
    "\n",
    "minkl_aim_max=np.max(minkl_aim,axis=2)\n",
    "minkl_aim_min=np.min(minkl_aim,axis=2)\n",
    "minkl_aim_range=minkl_aim_max-minkl_aim_min\n",
    "minkl_aim_normalized=(minkl_aim-minkl_aim_min[:,:,np.newaxis])/minkl_aim_range[:,:,np.newaxis]\n",
    "\n",
    "optbinidx_aim=np.argmin(totalvar_aim_normalized+minkl_aim_normalized,axis=2)\n",
    "optbinvals_aim=np.zeros((nexperiments,len(samplesizes)))\n",
    "for e in range(nexperiments):\n",
    "    for s in range(len(samplesizes)):\n",
    "        optbinvals_aim[e,s]=granularities[optbinidx_aim[e,s]]\n",
    "\n",
    "\n",
    "######\n",
    "# For EM-AIM evaluation:\n",
    "######\n",
    "varlearnedparams_em_aim=np.var(learnedparams_em_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities),numparams) \n",
    "totalvar_em_aim=np.sum(varlearnedparams_em_aim,axis=3) #shape: (nexperiments,len(samplesizes),len(granularities)) \n",
    "minkl_em_aim=np.min(klvals_em_aim,axis=1) #shape: (nexperiments,len(samplesizes),len(granularities))\n",
    "\n",
    "totalvar_em_aim_max=np.max(totalvar_em_aim,axis=2)\n",
    "totalvar_em_aim_min=np.min(totalvar_em_aim,axis=2)\n",
    "totalvar_em_aim_range=totalvar_aim_max-totalvar_em_aim_min\n",
    "totalvar_em_aim_normalized=\\\n",
    "(totalvar_em_aim-totalvar_em_aim_min[:,:,np.newaxis])/totalvar_em_aim_range[:,:,np.newaxis]\n",
    "\n",
    "minkl_em_aim_max=np.max(minkl_em_aim,axis=2)\n",
    "minkl_em_aim_min=np.min(minkl_em_aim,axis=2)\n",
    "minkl_em_aim_range=minkl_em_aim_max-minkl_em_aim_min\n",
    "minkl_em_aim_normalized=(minkl_em_aim-minkl_em_aim_min[:,:,np.newaxis])/minkl_em_aim_range[:,:,np.newaxis]\n",
    "\n",
    "optbinidx_em_aim=np.argmin(totalvar_em_aim_normalized+minkl_em_aim_normalized,axis=2)\n",
    "optbinvals_em_aim=np.zeros((nexperiments,len(samplesizes)))\n",
    "for e in range(nexperiments):\n",
    "    for s in range(len(samplesizes)):\n",
    "        optbinvals_em_aim[e,s]=granularities[optbinidx_em_aim[e,s]]\n",
    "        \n",
    "        \n",
    "######\n",
    "# Collecting all learned parameters:\n",
    "######       \n",
    "\n",
    "\n",
    "numbins=len(granularities)\n",
    "    \n",
    "bestparams_aim=np.zeros((nexperiments,len(samplesizes),numbins,numparams)) \n",
    "averageparams_aim=np.zeros((nexperiments,len(samplesizes),numbins,numparams)) \n",
    "bestparams_em_aim=np.zeros((nexperiments,len(samplesizes),numbins,numparams)) \n",
    "bestparams_em=np.zeros((nexperiments,len(samplesizes),numparams))\n",
    "\n",
    "for ex in range(nexperiments):\n",
    "    for i in range(len(samplesizes)):\n",
    "        for bs in range(numbins):\n",
    "            bestparams_aim[ex,i,bs,:]=learnedparams_aim[ex,np.argmin(klvals_aim[ex,:,i,bs]),i,bs,:]  \n",
    "            bestparams_em_aim[ex,i,bs,:]=learnedparams_em_aim[ex,np.argmin(klvals_em_aim[ex,:,i,bs]),i,bs,:] \n",
    "            averageparams_aim[ex,i,bs,:]=np.average(learnedparams_aim[ex,:,i,bs,:],axis=0)\n",
    "        ropt=np.argmin(emlikelihoods[ex,:,i])\n",
    "        bestparams_em[ex,i,:]=learnedparams_em[ex,ropt,i,:]\n",
    "\n",
    "##########\n",
    "# Evaluating against ground truth:\n",
    "##########\n",
    "        \n",
    "score_all_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),numbins))\n",
    "score_best_aim=np.zeros((nexperiments,len(samplesizes),numbins))\n",
    "score_best_aim_optbin=np.zeros((nexperiments,len(samplesizes)))\n",
    "score_average_aim=np.zeros((nexperiments,len(samplesizes),numbins))\n",
    "\n",
    "\n",
    "score_all_em_aim=np.zeros((nexperiments,nrestarts,len(samplesizes),numbins))\n",
    "score_best_em_aim=np.zeros((nexperiments,len(samplesizes),numbins))\n",
    "score_best_em_aim_optbin=np.zeros((nexperiments,len(samplesizes)))\n",
    "\n",
    "score_best_em=np.zeros((nexperiments,len(samplesizes)))\n",
    "score_aca=np.zeros((nexperiments,len(samplesizes)))\n",
    "\n",
    "#datastats[ex,i,0:numparams]=np.vstack(cd.acameanvar(sz)).ravel()\n",
    "\n",
    "for ex in range(nexperiments):\n",
    "    for i in range(len(samplesizes)):\n",
    "        score_best_em[ex,i]=aim.score(true,bestparams_em[ex,i,:],idx)\n",
    "        score_aca[ex,i]=aim.score(true, datastats[ex,i,0:numparams],idx)\n",
    "        score_best_aim_optbin[ex,i]=aim.score(true,bestparams_aim[ex,i,optbinidx_aim[ex,i],:],idx)\n",
    "        score_best_em_aim_optbin[ex,i]=aim.score(true,bestparams_em_aim[ex,i,optbinidx_em_aim[ex,i],:],idx)\n",
    "        for bs in range(numbins):\n",
    "            for rs in range(nrestarts):\n",
    "                score_all_aim[ex,rs,i,bs]=aim.score(true,learnedparams_aim[ex,rs,i,bs],idx)   \n",
    "                score_all_em_aim[ex,rs,i,bs]=aim.score(true,learnedparams_em_aim[ex,rs,i,bs],idx) \n",
    "            score_best_aim[ex,i,bs]=score_all_aim[ex,np.argmin(klvals_aim[ex,:,i,bs]),i,bs]\n",
    "            score_average_aim[ex,i,bs]=aim.score(true,averageparams_aim[ex,i,bs,:],-1)\n",
    "            score_best_em_aim[ex,i,bs]=score_all_em_aim[ex,np.argmin(klvals_em_aim[ex,:,i,bs]),i,bs]\n",
    "            \n",
    "#####\n",
    "# For time stats:\n",
    "#####\n",
    "\n",
    "time_aim=np.sum(timestats_aim,axis=2) # summing over the granularities; shape: (nexperiments,len(samplesizes))\n",
    "                                      # same as timestats_em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jitter=0.03\n",
    "\n",
    "legends=[]\n",
    "\n",
    "for b in range(len(granularities)):\n",
    "    legends.append(granularities[b])\n",
    "    \n",
    "\n",
    "#figure=plt.figure(figsize=(15,10)) \n",
    "figure=plt.figure(figsize=(12,8)) \n",
    "ax = figure.add_subplot(111)\n",
    "\n",
    "#mpl.rcParams['axes.labelsize']=20\n",
    "\n",
    "# #Individual bin sizes AIM:    \n",
    "# for bs in range(numbins):\n",
    "#     y=np.average(score_best_aim[:,:,bs],axis=0)\n",
    "#     yerr=np.std(score_best_aim[:,:,bs],axis=0)\n",
    "#     plt.errorbar((1+jitter*bs)*np.array(samplesizes),y,yerr,label=legends[bs])\n",
    "    \n",
    "#     y=np.average(score_average_aim[:,:,bs],axis=0)\n",
    "#     yerr=np.std(score_average_aim[:,:,bs],axis=0)\n",
    "#     plt.errorbar((1+jitter*bs)*np.array(samplesizes),y,yerr,label=\"avg\"+str(legends[bs]))\n",
    "    \n",
    "#ACA:\n",
    "y=np.average(score_aca[:,:],axis=0)\n",
    "yerr=np.std(score_aca[:,:],axis=0)\n",
    "ax.errorbar((1-2*jitter)*np.array(samplesizes),y,yerr,c='green',label='ACA')\n",
    "\n",
    "#EM:    \n",
    "y=np.average(score_best_em[:,:],axis=0)\n",
    "yerr=np.std(score_best_em[:,:],axis=0)\n",
    "ax.errorbar((1-jitter)*np.array(samplesizes),y,yerr,c='mediumblue',label='EM')\n",
    "\n",
    "\n",
    "    \n",
    "#Best binsize AIM:\n",
    "y=np.average(score_best_aim_optbin[:,:],axis=0)\n",
    "yerr=np.std(score_best_aim_optbin[:,:],axis=0)\n",
    "ax.errorbar((1-3*jitter)*np.array(samplesizes),y,yerr,c='red', label='AIM')\n",
    "#Best binsize EM-AIM:\n",
    "y=np.average(score_best_em_aim_optbin[:,:],axis=0)\n",
    "yerr=np.std(score_best_em_aim_optbin[:,:],axis=0)\n",
    "ax.errorbar((1-4*jitter)*np.array(samplesizes),y,yerr,c='darkviolet',label='EM-AIM')\n",
    "\n",
    "\n",
    "#Binsize:\n",
    "axright=ax.twinx()\n",
    "\n",
    "y=np.average(optbinvals_aim[:,:],axis=0)\n",
    "yerr=np.std(optbinvals_aim[:,:],axis=0)\n",
    "axright.errorbar(np.array(samplesizes),y,yerr,c='dimgray',label='# cells (AIM)')\n",
    "\n",
    "y=np.average(optbinvals_em_aim[:,:],axis=0)\n",
    "yerr=np.std(optbinvals_em_aim[:,:],axis=0)\n",
    "axright.errorbar((1+jitter)*np.array(samplesizes),y,yerr,c='lightgray',label='# cells (EM-AIM)')\n",
    "\n",
    "# Construct the legend\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "linesr, labelsr = axright.get_legend_handles_labels()\n",
    "#axright.legend(lines + linesr, labels + labelsr) # use this for local legend inside plot\n",
    "# axright.legend(lines + linesr, labels + labelsr,loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "#          ncol=6, fontsize=15, fancybox=True, shadow=True) # use this for separate legend outside\n",
    "\n",
    "\n",
    "# ax.set_ylabel(\"squared error\", fontsize=20)\n",
    "# axright.set_ylabel(\"# cells\", fontsize=20)\n",
    "# ax.set_xlabel(\"sample size\", fontsize=20)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.xaxis.set_tick_params(labelsize=25)\n",
    "ax.yaxis.set_tick_params(labelsize=25)\n",
    "axright.yaxis.set_tick_params(labelsize=25)\n",
    "#ax.set_ylim((0,0.2))\n",
    "#plt.legend()    \n",
    "plt.show()         \n",
    "\n",
    "print(retrieve['readme'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
